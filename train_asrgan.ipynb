{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.99\n",
    "\n",
    "POOL_SIZE = BATCH_SIZE * 10\n",
    "RESTORE_CHECKPOINT = False\n",
    "\n",
    "LOAD_GAN_WEIGHTS = True\n",
    "\n",
    "SAVE_GAN_MODEL = True\n",
    "SAVE_EMA_MODEL = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "from glob import glob\n",
    "from utils.train import gan_inner_step, AverageModelWeights\n",
    "\n",
    "from keras.optimizer_v2.adam import Adam\n",
    "\n",
    "from utils.data import load_function, feed_data, PoolData\n",
    "from utils.data import feed_props_1, feed_props_2\n",
    "from utils.data import usm_sharpener\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_optimizer = Adam(learning_rate=LEARNING_RATE,\n",
    "                      beta_1=BETA_1, beta_2=BETA_2)\n",
    "disc_optimizer = Adam(learning_rate=LEARNING_RATE,\n",
    "                       beta_1=BETA_1, beta_2=BETA_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.models import RRDBNet\n",
    "\n",
    "gan_model = RRDBNet()\n",
    "\n",
    "if LOAD_GAN_WEIGHTS:\n",
    "    gan_model.load_weights('./checkpoint_weights/last_weights')\n",
    "\n",
    "gan_model.build((None, 256, 256, 3))\n",
    "\n",
    "ema_gan_model = RRDBNet()\n",
    "ema_gan_model.build((None, 256, 256, 3))\n",
    "\n",
    "ema_api = AverageModelWeights(ema_gan_model, gan_model.get_weights())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.models import Vgg19FeaturesModel, UNetDiscriminator\n",
    "\n",
    "discriminator = UNetDiscriminator()\n",
    "vgg_model = Vgg19FeaturesModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_gan_checkpoints'\n",
    "ema_checkpoint_dir = './ema_training_gan_checkpoints'\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator=gan_model, gen_optimizer=gen_optimizer,\n",
    "                                 discriminator=discriminator, disc_optimizer=disc_optimizer)\n",
    "\n",
    "ema_checkpoint_prefix = os.path.join(ema_checkpoint_dir, \"ema_ckpt\")\n",
    "ema_checkpoint = tf.train.Checkpoint(model=ema_gan_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RESTORE_CHECKPOINT:\n",
    "    print(\"loading training checkpoints: \")\n",
    "    print(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "    print(\"loading EMA training checkpoints: \")\n",
    "    print(tf.train.latest_checkpoint(ema_checkpoint_dir))\n",
    "    ema_checkpoint.restore(tf.train.latest_checkpoint(ema_checkpoint_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.abspath(\"./DIV2K_train_HR/*.png\")\n",
    "train_images_paths = sorted(glob(data_path))\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images_paths))\n",
    "train_dataset = train_dataset.shuffle(len(train_images_paths))\n",
    "train_dataset = train_dataset.map(\n",
    "    load_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_generator = train_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "pool_train_data = PoolData(POOL_SIZE, BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(gt_images, usm_gt_images, lq_images):\n",
    "    return gan_inner_step(\n",
    "        gt_images, usm_gt_images, lq_images,\n",
    "        gan_model, discriminator, vgg_model,\n",
    "        gen_optimizer, disc_optimizer\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = int(len(train_images_paths) // BATCH_SIZE)\n",
    "\n",
    "epochs = EPOCHS\n",
    "start_epoch = 0\n",
    "\n",
    "train_loss_metric = tf.keras.metrics.Mean()\n",
    "loss_results = []\n",
    "\n",
    "discriminator_loss_metric = tf.keras.metrics.Mean()\n",
    "discriminator_loss_results = []\n",
    "\n",
    "generator_loss_metric = tf.keras.metrics.Mean()\n",
    "generator_loss_results = []\n",
    "\n",
    "perceptual_loss_metric = tf.keras.metrics.Mean()\n",
    "perceptual_loss_results = []\n",
    "\n",
    "l1_loss_metric = tf.keras.metrics.Mean()\n",
    "l1_loss_results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    print(\"Start Training\")\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        train_loss_metric.reset_states()\n",
    "        discriminator_loss_metric.reset_states()\n",
    "        generator_loss_metric.reset_states()\n",
    "        perceptual_loss_metric.reset_states()\n",
    "        l1_loss_metric.reset_states()\n",
    "\n",
    "        epoch_time = time.time()\n",
    "        batch_time = time.time()\n",
    "        step = 0\n",
    "\n",
    "        epoch_count = f\"0{epoch + 1}/{epochs}\" if epoch < 9 else f\"{epoch + 1}/{epochs}\"\n",
    "\n",
    "        for img, first_kernel, second_kernel, sinc_kernel in train_generator:\n",
    "            gt_img, lq_img = feed_data(img, first_kernel, second_kernel, sinc_kernel, [\n",
    "                                       feed_props_1, feed_props_2])\n",
    "            gt_img, lq_img = pool_train_data.get_pool_data(gt_img, lq_img)\n",
    "\n",
    "            usm_gt_img = usm_sharpener.sharp(gt_img)\n",
    "\n",
    "            total_generator_loss, gen_loss, perceptual_loss, l1_loss, disc_loss = train_step(\n",
    "                gt_img, usm_gt_img, lq_img)\n",
    "\n",
    "            print('\\r', 'Epoch', epoch_count, '| Step', f\"{step}/{train_steps}\",\n",
    "                  '| disc_loss:', f\"{disc_loss:.5f}\", '| total_generator_loss:', f\"{total_generator_loss:.5f}\",\n",
    "                  \"| Step Time:\", f\"{time.time() - batch_time:.2f}\", end='')\n",
    "\n",
    "            train_loss_metric.update_state(total_generator_loss + disc_loss)\n",
    "            total_loss = train_loss_metric.result().numpy()\n",
    "            loss_results.append(total_loss)\n",
    "\n",
    "            discriminator_loss_metric.update_state(disc_loss)\n",
    "            discriminator_loss = discriminator_loss_metric.result().numpy()\n",
    "            discriminator_loss_results.append(discriminator_loss)\n",
    "\n",
    "            generator_loss_metric.update_state(gen_loss)\n",
    "            loss = generator_loss_metric.result().numpy()\n",
    "            generator_loss_results.append(loss)\n",
    "\n",
    "            perceptual_loss_metric.update_state(perceptual_loss)\n",
    "            loss = perceptual_loss_metric.result().numpy()\n",
    "            perceptual_loss_results.append(loss)\n",
    "\n",
    "            l1_loss_metric.update_state(l1_loss)\n",
    "            loss = l1_loss_metric.result().numpy()\n",
    "            l1_loss_results.append(loss)\n",
    "\n",
    "            step += 1\n",
    "\n",
    "            batch_time = time.time()\n",
    "\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "        ema_api.compute_ema_weights(gan_model)\n",
    "        ema_checkpoint.save(file_prefix=ema_checkpoint_prefix)\n",
    "\n",
    "        print('\\r', 'Epoch', epoch_count, '| Step', f\"{step}/{train_steps}\",\n",
    "              '| disc_loss:', f\"{discriminator_loss:.5f}\", '| total_generator_loss:', f\"{total_loss:.5f}\",\n",
    "              \"| Epoch Time:\", f\"{time.time() - epoch_time:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(epochs)\n",
    "\n",
    "if SAVE_GAN_MODEL:\n",
    "    gan_model.save('./gan_model')\n",
    "\n",
    "if SAVE_EMA_MODEL:\n",
    "    ema_gan_model.save(\"./gan_ema_model\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcd8f4151858495978d563a1180e22ca9796714efe5ba17959aaeac20906768e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensordock')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
